{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- TwitterGeolocationScraper running. This may take a minute to update the webdriver. --\n",
      "Page loading not complete\n",
      "remaining rate limit: 249 | tweet_df length: 20\n",
      "remaining rate limit: 248 | tweet_df length: 20\n",
      "remaining rate limit: 247 | tweet_df length: 20\n",
      "remaining rate limit: 246 | tweet_df length: 20\n",
      "remaining rate limit: 245 | tweet_df length: 20\n",
      "remaining rate limit: 244 | tweet_df length: 20\n",
      "remaining rate limit: 243 | tweet_df length: 20\n",
      "remaining rate limit: 242 | tweet_df length: 20\n",
      "remaining rate limit: 241 | tweet_df length: 20\n",
      "remaining rate limit: 240 | tweet_df length: 20\n",
      "remaining rate limit: 239 | tweet_df length: 20\n",
      "remaining rate limit: 238 | tweet_df length: 20\n",
      "remaining rate limit: 237 | tweet_df length: 20\n",
      "remaining rate limit: 236 | tweet_df length: 20\n",
      "remaining rate limit: 235 | tweet_df length: 20\n",
      "remaining rate limit: 234 | tweet_df length: 20\n",
      "remaining rate limit: 233 | tweet_df length: 20\n",
      "remaining rate limit: 232 | tweet_df length: 20\n",
      "remaining rate limit: 231 | tweet_df length: 20\n",
      "remaining rate limit: 230 | tweet_df length: 20\n",
      "remaining rate limit: 229 | tweet_df length: 20\n",
      "remaining rate limit: 228 | tweet_df length: 20\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "from twitscrape.twitter_scraper import TwitterGeolocationScraper \n",
    "# twitscrape is a package I built and distributed as an aside learning experiment to this project. I plan to work on it further so the import method might change from the above.\n",
    "# https://github.com/christywastaken/twitscrape \n",
    "# https://pypi.org/project/twitscrape/ \n",
    "\n",
    "newcastle_latitude = 54.975029\n",
    "newcastle_longitude = -1.612477\n",
    "search_radius_km = 15.0\n",
    "summer_solstice_week_scraper = TwitterGeolocationScraper(start_date='2022-06-20', end_date='2022-06-28', latitude=newcastle_latitude, longitude=newcastle_longitude, radius=search_radius_km, filter_links=True, filter_replies=True, is_headless=True)\n",
    "summer_solstice_week_df = summer_solstice_week_scraper.run()\n",
    "# Creates dataframe of all the tweets in Newcastle-Upon-Tyne for a 15km radius the week around the summer solstice 2022. Links and replies filtered out. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only join an iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#Clean data to store in SQL (dataframe columns 'hashtags' and 'media_url' are lists.)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m summer_solstice_week_df[\u001b[39m'\u001b[39m\u001b[39mhashtags\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m summer_solstice_week_df[\u001b[39m'\u001b[39;49m\u001b[39mhashtags\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mapply(\u001b[39mlambda\u001b[39;49;00m x: \u001b[39m'\u001b[39;49m\u001b[39m|\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m.\u001b[39;49mjoin(x))\n\u001b[1;32m      3\u001b[0m summer_solstice_week_df[\u001b[39m'\u001b[39m\u001b[39mmedia_url\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m summer_solstice_week_df[\u001b[39m'\u001b[39m\u001b[39mmedia_url\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: \u001b[39m'\u001b[39m\u001b[39m|\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(x))\n\u001b[1;32m      4\u001b[0m conn \u001b[39m=\u001b[39m sqlite3\u001b[39m.\u001b[39mconnect(\u001b[39m'\u001b[39m\u001b[39mtwitter_sentiment_analysis.db\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Code/learn/purple-beard/capstone/sentiment_analysis/venv/lib/python3.11/site-packages/pandas/core/series.py:4771\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4661\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[1;32m   4662\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   4663\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4666\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   4667\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[1;32m   4668\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4669\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4670\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4769\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4770\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4771\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[0;32m~/Documents/Code/learn/purple-beard/capstone/sentiment_analysis/venv/lib/python3.11/site-packages/pandas/core/apply.py:1123\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[1;32m   1122\u001b[0m \u001b[39m# self.f is Callable\u001b[39;00m\n\u001b[0;32m-> 1123\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m~/Documents/Code/learn/purple-beard/capstone/sentiment_analysis/venv/lib/python3.11/site-packages/pandas/core/apply.py:1174\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1172\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1173\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[0;32m-> 1174\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[1;32m   1175\u001b[0m             values,\n\u001b[1;32m   1176\u001b[0m             f,\n\u001b[1;32m   1177\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[1;32m   1178\u001b[0m         )\n\u001b[1;32m   1180\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1181\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1182\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1183\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/Documents/Code/learn/purple-beard/capstone/sentiment_analysis/venv/lib/python3.11/site-packages/pandas/_libs/lib.pyx:2924\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#Clean data to store in SQL (dataframe columns 'hashtags' and 'media_url' are lists.)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m summer_solstice_week_df[\u001b[39m'\u001b[39m\u001b[39mhashtags\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m summer_solstice_week_df[\u001b[39m'\u001b[39m\u001b[39mhashtags\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: \u001b[39m'\u001b[39;49m\u001b[39m|\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m.\u001b[39;49mjoin(x))\n\u001b[1;32m      3\u001b[0m summer_solstice_week_df[\u001b[39m'\u001b[39m\u001b[39mmedia_url\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m summer_solstice_week_df[\u001b[39m'\u001b[39m\u001b[39mmedia_url\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: \u001b[39m'\u001b[39m\u001b[39m|\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(x))\n\u001b[1;32m      4\u001b[0m conn \u001b[39m=\u001b[39m sqlite3\u001b[39m.\u001b[39mconnect(\u001b[39m'\u001b[39m\u001b[39mtwitter_sentiment_analysis.db\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: can only join an iterable"
     ]
    }
   ],
   "source": [
    "#Store to SQL DB\n",
    "conn = sqlite3.connect('twitter_sentiment_analysis.db')\n",
    "summer_solstice_week_df.to_sql('summer_solstice_week', conn, if_exists='replace', index=False)\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
